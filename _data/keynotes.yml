- firstname: Boris
  lastname: Koldehofe
  title: TBA
  affiliation: Technical University of Ilmenau, Germany
  image: /img/keynotes/boris.jpg
#  abstract: "Freedom of the press is under threat worldwide, and the quality of information that people have access to is dangerously degraded, under the joint threat of non-democratic governments and fake information propagation. The press as an industry needs powerful data management tools to help them interpret the complex reality surrounding us. Since 2018, I have been cooperating with journalists from Le Monde, France’s leading newspaper, in devising tools for analyzing large and heterogeneuos data sources that they are interested in. This research has been embodied in ConnectionLens, a graph ETL tool capable of ingesting heterogeneous data sources into a graph, enriched (with the help of ML methods) with entities extracted from data of any type. On such integrated graphs, we devised novel algorithms for keyword search, and combine them in more recent research with structured querying. The talk describes the architecture and main algorithmic challenges in building and exploiting ConnectionLens graphs, illustrated in particular on an application where we study conflicts of interest in the biomedical domain. This is joint work with A. Anadiotis, O. Balalau, H. Galhardas and many others. ConnectionLens Web site (papers+code): https://team.inria.fr/cedar/connectionlens/. This research has been funded by Agence Nationale de la Recherche AI Chair SourcesSay (https://sourcessay.inria.fr)."
    
  biography: Boris Koldehofe is a Full Professor at the Technical University of Ilmenau, leading the Distributed and Operating Systems Group at the department of Computer Science and Automation. He received a Ph.D. degree from Chalmers University of Technology, Gothenburg, Sweden, in 2005. Since then, he has worked in the field of distributed and network-centric computing systems at the EPFL (PostDoc), the University of Stuttgart, the Technical University of Darmstadt (Senior researcher and lecturer), and the University of Groningen (Full professor). He has a long-standing interest in event-based and stream processing systems covering issues related to scalability, performance, mobility, reliability and security. His current research focuses complementary on software-defined networks, adaptive communication middleware and distributed in-network computing. He has contributed to more than 100 scientific publications in major journals, e.g., the IEEE Transactions on Networking (ToN) and the IEEE Transactions on Parallel and Distributed Systems, and conferences, e.g., the ACM/USENIX Middleware and the ACM DEBS conferences. He has also contributed to many academic services at major conferences and journals. In the context of the ACM DEBS conference, he has served in several roles in the organizing and steering committee, e.g., as TPC Co-Chair in 2017, and as the General Chair in 2019. He has also served as a Tutorial Speaker for the ACM/USENIX Middleware, ACM DEBS, GI, and NetSys conferences.
#    
#  paper:
#    title: 
#    authors: 
#    doi:
#
- firstname: Yvonne-Anne
  lastname: Pignolet
  title: "Internet Computer Protocol: democratic evolution of a web3 platform"
  affiliation: DFINITY
  image: /img/keynotes/yap.jpg
  abstract: Recent technological advances have enabled the efficient execution of decentralized web3 applications and smart contracts. The Internet Computer Protocol (ICP) is a fast and efficient decentralized blockchain-based system for the execution of general-purpose applications in the form of smart contracts. In particular, the ICP’s execution, governance and evolution are controlled by different parties in a trustless and fault-tolerant manner instead of a central entity. In this talk, I will give an overview of the ICP, followed by a discussion of the challenges the IC faces to facilitate upgrading itself through voting by ICP token holders and present our approach to tackle them.
#    
  biography: Yvonne-Anne Pignolet's work is centered around distributed systems, ranging from the design and analysis of algorithms for reliable and efficient distributed systems despite failures and malicious behaviour to complex network analysis. After her PhD at ETH Zurich in 2009 she was a postdoc at IBM Research Zurich and Ben Gurion University, Be'er Sheva. She worked for 8 years at ABB Corporate Research, Switzerland mostly devoted to research on communication systems for industrial and power systems, as a Principal Scientist in her final role. In 2019, she joined DFINITY, where she now leads teams of researchers building and improving the Internet Computer.
#    
#  paper:
#    title: 
#    authors: 
#    doi:
#
- firstname: Patrick
  lastname: Eugster
  title: TBA
  affiliation: Università della Svizzera Italiana (USI), Lugano, Switzerland
  image: /img/keynotes/patrick.png
#  abstract: "Materialize is a system that presents to users as SQL against continually changing data. It transforms inbound streams of *change data capture* events into streams that exactly correspond to transformed data, and maintains indexed representations of the results for efficient access and operation. SQL over changing data is surprisingly (for me) expressive: Materialize can operate on unbounded data, implement data-driven windows, and perform event-based queries, all with ANSI standard SQL. We will discuss what an event-based SQL system looks like, SQL idioms that give rise to traditionally stream-exclusive behavior, and how one architects such a system to scale across multiple dimensions."
#    
  biography: Patrick is professor of computer science at the Università della Svizzera italiana (USI) in Lugano, Switzerland, where he leads the Software Systems (SWYSTEMS) research group. Prior to that Patrick was a regular faculty member at Purdue University (2005–2016) and TU Darmstadt (2014–2017), and a visiting professor at MIT (2012–2013). His research has been awarded by several public funding agencies (e.g., NSF, ERC, DARPA, SNSF) as well as corporate partners (e.g., Cisco, Facebook, Google, HP, IBM, Meta, NetApp, Northrop-Grumman, SAP) through respective programs. Patrick is interested in all aspects of dependable distributed systems, in particular the intersection with programming languages and networks. Patrick served as PC chair for ACM OOPSLA’15, returning as associate PC chair for ACM OOPSLA’23, and currently serves as associate editor for IEEE Transactions on Software Engineering. But before all that, Patrick started his academic path as an early contributor to event-based systems and DEBS, serving also as PC co-chair for DEBS'12, so he is particularly excited to return.
#    
#  paper:
#    title: 
#    authors: 
#    doi:
#
#- firstname: Till
#  lastname: Rohrmann
#  title: Rethinking how distributed applications are built
#  affiliation: Ververica
#  image: /img/keynotes/till.jpeg
#  abstract: In our more and more connected world where people are used to managing their lives via digital services, it has become mandatory for a successful company to build applications that can scale with the popularity of the company’s services. Scalability is not the only requirement but similarly important is that modern applications are highly available and fast because users are not willing to wait in our ever faster moving world. Due to this, we have seen a shift from the classic monolith towards micro service architectures which promise to be more easily scalable. The emergence of serverless functions further strengthened this trend more recently. By implementing a micro service architecture, application developers are all of a sudden exposed to the realm of distributed applications with its seemingly limitless scalability but also its pitfalls nobody tells you about upfront. So instead of solving business domain problems, developers find themselves fighting with race conditions, distributed failures, inconsistencies and in general a drastically increased complexity. In order to solve some of these problems, people introduce endless retries, timeouts, sagas and distributed transactions. These band aids can quickly result in a not so scalable system that is brittle and hard to maintain. The underlying problem is that developers are responsible for ensuring reliable communication and consistent state changes. Having a system that takes care of these aspects could drastically reduce the complexity of developing scalable distributed applications. By inverting the traditional control-flow from application-to-database to database-to-application, we can put the database in charge of ensuring reliable communication and consistent state changes and, thus, freeing the developer to think about it. In this keynote, I want to explore the idea of putting the database in charge of driving the application logic using the example of Stateful Functions, a library built on top of Apache Flink that follows this idea. I will explain how Stateful Functions achieves scalability and consistency but also what its limitations are. Based on these results, I would like to sketch the requirements for a runtime that can truly realise the full potential of Stateful Functions and discuss with you ideas how it could be implemented.
#    
#  biography: Till is a PMC member of Apache Flink and a cofounder of Ververica. During his time at Ververica, his work focused on enhancing Flink’s scalability and high availability. He also bootstrapped Flink’s CEP and the initial ML library. Nowadays, Till focuses on making the development of distributed applications easier by employing stream processing techniques to this space.
#    
#  paper:
#    title: 
#    authors: 
#    doi:
